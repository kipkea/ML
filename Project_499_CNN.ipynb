{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39daa839",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NongNNew/Project_499/blob/main/Project_499_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hW4AHGmEVrk8",
   "metadata": {
    "id": "hW4AHGmEVrk8"
   },
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nkYRb02rScfH",
   "metadata": {
    "id": "nkYRb02rScfH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Nq11bNFAbCci",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq11bNFAbCci",
    "outputId": "d494ab61-8387-4a79-e91b-a9746e1f1706",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python_speech_features in d:\\programdata\\anaconda3\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: librosa in d:\\programdata\\anaconda3\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: google in d:\\programdata\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: tensorflow in d:\\programdata\\anaconda3\\lib\\site-packages (2.8.3)\n",
      "Requirement already satisfied: scikeras in d:\\programdata\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: pooch>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.9.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: joblib>=0.14 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: decorator>=4.0.10 in d:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\programdata\\anaconda3\\lib\\site-packages (from google) (4.11.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in d:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa) (0.39.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->google) (2.3.2.post1)\n",
      "Requirement already satisfied: pycparser in d:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features librosa google tensorflow scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fssuU2ucR1vy",
   "metadata": {
    "id": "fssuU2ucR1vy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal.windows import hamming\n",
    "from sklearn.metrics import classification_report,  plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "y1vuUlgJSKkC",
   "metadata": {
    "id": "y1vuUlgJSKkC"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gJVdtdww87RO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJVdtdww87RO",
    "outputId": "bdb598e1-c842-462f-b6c2-4f0ea427b6d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Project_499' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Upload audio files from github\n",
    "!git clone https://github.com/NongNNew/Project_499.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BRWP2IrOShCH",
   "metadata": {
    "id": "BRWP2IrOShCH"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "EHnDUT5YejVV",
   "metadata": {
    "id": "EHnDUT5YejVV"
   },
   "outputs": [],
   "source": [
    "# Name of vegetables and fruits 52 types of 56 classes\n",
    "fruit_veget = ['กระชาย','กระท้อน','กระเทียม1','กระเทียม2','กระเพรา','กล้วยน้ำว้า','กล้วยหอม',\n",
    "               'ข้าวโพด','ไข่น้ำ',\n",
    "               'ตะขบไทย','ตะไคร้',\n",
    "               'ถั่วฝักยาว','ถั่วลันเตา','ถั่วลิสง',\n",
    "               'ทับทิม',\n",
    "               'น้อยหน่า','น้ำเต้า',\n",
    "               'ผักกระเฉด','ผักกุยช่าย','ผักขึ้นช่าย','ผักชะอม','ผักชี','ผักชีฝรั่ง','ผักตำลึง',\n",
    "               'มะปราง','มะพลับ','มะละกอ','มะกรูด','มะเขือพวง','มะเขือเทศ','มะระ','มะรุม','มะตูม','มันแกว1','มันแกว2','มันเทศ','มันฝรั่ง','มันสำปะหลัง',\n",
    "               'บวบ','ใบชะพลู1','ใบชะพลู2','ใบบัวบก','ใบแมงลัก','ใบยอ',\n",
    "               'พริกขี้หนู','พริกสด','พุทรา','เพกา',\n",
    "               'ฝรั่ง',\n",
    "               'ฟัก','ฟักทอง',\n",
    "               'สับปะรด','สะเดา','สะระแหน่',\n",
    "               'หัวหอม1','หัวหอม2']\n",
    "\n",
    "# Audio data source\n",
    "source = {'audio_time':[],\n",
    "          'sampling_rate':[],\n",
    "          'feature_extraction':[],\n",
    "          'label':[],\n",
    "          'description':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "_XRqKtGBeW_1",
   "metadata": {
    "id": "_XRqKtGBeW_1"
   },
   "outputs": [],
   "source": [
    "def feature_mfcc(y,sr):\n",
    "    return (python_speech_features.mfcc(signal=y, \n",
    "                                    samplerate=sr, \n",
    "                                    winlen= 512/sr, \n",
    "                                    winstep= 160/sr,\n",
    "                                    numcep= 13,\n",
    "                                    nfilt= 40, \n",
    "                                    nfft= 512,\n",
    "                                    lowfreq= 0,\n",
    "                                    highfreq= None,\n",
    "                                    preemph= 0.97, \n",
    "                                    ceplifter= 0,\n",
    "                                    winfunc= hamming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tixApnAUy5tv",
   "metadata": {
    "id": "tixApnAUy5tv"
   },
   "outputs": [],
   "source": [
    "for types in fruit_veget:\n",
    "    #audio_files = glob('/content/Project_499/Record_audio/' + str(types) + '/*.wav')\n",
    "    audio_files = glob('./Record_audio/' + str(types) + '/*.wav')\n",
    "\n",
    "    for audio in audio_files:\n",
    "        y,sr = librosa.load(audio,duration=5,offset=0)\n",
    "        source['description'].append(str(types))\n",
    "        source['audio_time'].append(y)\n",
    "        source['sampling_rate'].append(sr)\n",
    "        source['feature_extraction'].append(feature_mfcc(y,sr))\n",
    "        source['label'].append(fruit_veget.index(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8B6cSV4Ckude",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8B6cSV4Ckude",
    "outputId": "da931fe0-ea27-4751-fb90-4e1b642bf718"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_time</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>feature_extraction</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.5258789e-05, -3.0517578e-05, 4.5776367e-05,...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-13.895163210723114, -10.534242113550562, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>กระชาย</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00010681152, -0.00010681152, -0.0001525878...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-14.047682378884087, -10.559749338871004, 1....</td>\n",
       "      <td>0</td>\n",
       "      <td>กระชาย</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0004119873, 0.00061035156, 0.0005340576, 0....</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-14.031458292064183, -9.719918182168307, 3.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>กระชาย</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.5258789e-05, -3.0517578e-05, 6.1035156e-05,...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-14.225420647550473, -11.767209141048717, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>กระชาย</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-9.1552734e-05, -0.00012207031, -0.0001373291...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-13.95247445826829, -10.979968172429752, 1.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>กระชาย</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>[-1.5258789e-05, -3.0517578e-05, -0.0001525878...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-13.975110034884988, -11.686919071361821, -0...</td>\n",
       "      <td>55</td>\n",
       "      <td>หัวหอม2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>[-0.0001373291, -9.1552734e-05, -7.6293945e-05...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-14.082713493333289, -12.10106746611324, -0....</td>\n",
       "      <td>55</td>\n",
       "      <td>หัวหอม2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>[-0.00018310547, -0.00019836426, -0.0002288818...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-13.811710436355032, -12.034727613545233, 0....</td>\n",
       "      <td>55</td>\n",
       "      <td>หัวหอม2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>[-0.00018310547, -0.0002593994, -0.00021362305...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-14.051788496188221, -10.373070308117178, 4....</td>\n",
       "      <td>55</td>\n",
       "      <td>หัวหอม2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>[-0.00010681152, -0.00010681152, -0.0002136230...</td>\n",
       "      <td>22050</td>\n",
       "      <td>[[-13.965644315403711, -9.922440291030707, 1.8...</td>\n",
       "      <td>55</td>\n",
       "      <td>หัวหอม2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             audio_time  sampling_rate  \\\n",
       "0     [1.5258789e-05, -3.0517578e-05, 4.5776367e-05,...          22050   \n",
       "1     [-0.00010681152, -0.00010681152, -0.0001525878...          22050   \n",
       "2     [0.0004119873, 0.00061035156, 0.0005340576, 0....          22050   \n",
       "3     [1.5258789e-05, -3.0517578e-05, 6.1035156e-05,...          22050   \n",
       "4     [-9.1552734e-05, -0.00012207031, -0.0001373291...          22050   \n",
       "...                                                 ...            ...   \n",
       "1095  [-1.5258789e-05, -3.0517578e-05, -0.0001525878...          22050   \n",
       "1096  [-0.0001373291, -9.1552734e-05, -7.6293945e-05...          22050   \n",
       "1097  [-0.00018310547, -0.00019836426, -0.0002288818...          22050   \n",
       "1098  [-0.00018310547, -0.0002593994, -0.00021362305...          22050   \n",
       "1099  [-0.00010681152, -0.00010681152, -0.0002136230...          22050   \n",
       "\n",
       "                                     feature_extraction  label description  \n",
       "0     [[-13.895163210723114, -10.534242113550562, 0....      0      กระชาย  \n",
       "1     [[-14.047682378884087, -10.559749338871004, 1....      0      กระชาย  \n",
       "2     [[-14.031458292064183, -9.719918182168307, 3.0...      0      กระชาย  \n",
       "3     [[-14.225420647550473, -11.767209141048717, 0....      0      กระชาย  \n",
       "4     [[-13.95247445826829, -10.979968172429752, 1.8...      0      กระชาย  \n",
       "...                                                 ...    ...         ...  \n",
       "1095  [[-13.975110034884988, -11.686919071361821, -0...     55     หัวหอม2  \n",
       "1096  [[-14.082713493333289, -12.10106746611324, -0....     55     หัวหอม2  \n",
       "1097  [[-13.811710436355032, -12.034727613545233, 0....     55     หัวหอม2  \n",
       "1098  [[-14.051788496188221, -10.373070308117178, 4....     55     หัวหอม2  \n",
       "1099  [[-13.965644315403711, -9.922440291030707, 1.8...     55     หัวหอม2  \n",
       "\n",
       "[1100 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tranform dictionary to dataframe \n",
    "df = pd.DataFrame.from_dict(source)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "T7yzW3hnmuyB",
   "metadata": {
    "id": "T7yzW3hnmuyB"
   },
   "outputs": [],
   "source": [
    "\n",
    "Test = pd.DataFrame(columns=source.keys())\n",
    "\n",
    "# Create test data\n",
    "\n",
    "for description in np.unique(df['description']):\n",
    "    imp_test = df[df['description']==description].sample(5,random_state=1)\n",
    "    Test = pd.concat([Test,imp_test], axis=0)\n",
    "Train = df.drop(index=Test.index)\n",
    "\n",
    "Valid = pd.DataFrame(columns=source.keys())\n",
    "for description in np.unique(Train['description']):\n",
    "    imp_test = Train[Train['description']==description].sample(3,random_state=1)\n",
    "    Valid = pd.concat([Valid,imp_test], axis=0)\n",
    "Train = Train.drop(index=Valid.index)\n",
    "\n",
    "X_train = np.array(Train['feature_extraction'].to_list())\n",
    "X_test = np.array(Test['feature_extraction'].to_list())\n",
    "X_valid = np.array(Valid['feature_extraction'].to_list())\n",
    "y_train = np.array(Train['label'].to_list())\n",
    "y_test = np.array(Test['label'].to_list())\n",
    "y_valid = np.array(Valid['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mSV3u9RmEU7h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSV3u9RmEU7h",
    "outputId": "713be782-09b5-4c6e-e8d4-64fc884943e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((660,), (165,), (275,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of data\n",
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r7RGaVViSrwg",
   "metadata": {
    "id": "r7RGaVViSrwg"
   },
   "source": [
    "## Build cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77wMVqve6W8f",
   "metadata": {
    "id": "77wMVqve6W8f"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(activation='relu',dropout=0.25,optimizer='adam'):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "    model = None\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, 5, input_shape=(X_train.shape[1], X_train.shape[2], 1), activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(64, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(len(np.unique(df['label'])), activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0xv_Bj3d310E",
   "metadata": {
    "id": "0xv_Bj3d310E"
   },
   "source": [
    "## Find each hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "YEIO2YO536Rb",
   "metadata": {
    "id": "YEIO2YO536Rb"
   },
   "outputs": [],
   "source": [
    "# find hyperparameter\n",
    "epochs = [20,30,50,100,150]\n",
    "batch_size = [16,32,50,64,80,100]\n",
    "dropout = [0.2,0.25,0.3,0.4]\n",
    "lr = [0.001,0.01,0.1,0.2] \n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0UMa3i_4ec3",
   "metadata": {
    "id": "f0UMa3i_4ec3"
   },
   "source": [
    "### epoachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L8wXVzcE4GSZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8wXVzcE4GSZ",
    "outputId": "ba3186ec-57b6-4c84-9fb0-97ea75799204"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\scikeras\\wrappers.py:301: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YFdH7ttM4hwN",
   "metadata": {
    "id": "YFdH7ttM4hwN"
   },
   "source": [
    "### batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mIYS7nEu4mgt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIYS7nEu4mgt",
    "outputId": "2a1c5313-ffee-4841-b9ce-7d278ae7e700"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0,epochs=30)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(batch_size=batch_size)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xfQsiSAl43I2",
   "metadata": {
    "id": "xfQsiSAl43I2"
   },
   "source": [
    "### dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GzLr5_9X6AIP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzLr5_9X6AIP",
    "outputId": "fa787d1f-5aaa-4835-c061-6c790a619895"
   },
   "outputs": [],
   "source": [
    "# find hyperparameter\n",
    "epochs = [30]\n",
    "batch_size = [64]\n",
    "dropout = [0.2,0.25,0.3,0.4]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(dropout=dropout,epochs=epochs,batch_size=batch_size)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rJVsxC7P6dwE",
   "metadata": {
    "id": "rJVsxC7P6dwE"
   },
   "source": [
    "### activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-mL5xc076gCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mL5xc076gCq",
    "outputId": "3f1600ea-e68d-4a86-a596-c290bf24e63f"
   },
   "outputs": [],
   "source": [
    "# find hyperparameter\n",
    "epochs = [30]\n",
    "batch_size = [64]\n",
    "dropout = [0.2]\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(dropout=dropout,epochs=epochs,batch_size=batch_size,activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZcQCVNq9af0",
   "metadata": {
    "id": "IZcQCVNq9af0"
   },
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Em9LGSMJ9ZJ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Em9LGSMJ9ZJ0",
    "outputId": "bcfd9f67-1547-46a8-933f-14e8d6408391"
   },
   "outputs": [],
   "source": [
    "# find hyperparameter\n",
    "epochs = [30]\n",
    "batch_size = [64]\n",
    "dropout = [0.2]\n",
    "activation = ['relu']\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(dropout=dropout,epochs=epochs,batch_size=batch_size,activation=activation,optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y_KIFZ8m8LPP",
   "metadata": {
    "id": "y_KIFZ8m8LPP"
   },
   "source": [
    "### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2iP4ZqcQ9Pna",
   "metadata": {
    "id": "2iP4ZqcQ9Pna"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(activation='relu',dropout=0.25,optimizer='adam',learn_rate=0.001):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "    model = None\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, 5, input_shape=(X_train.shape[1], X_train.shape[2], 1), activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(64, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(len(np.unique(df['label'])), activation='softmax'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=learn_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m2CU2Lkj8Ope",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2CU2Lkj8Ope",
    "outputId": "42074c40-6426-4f8e-f049-9c006698346e"
   },
   "outputs": [],
   "source": [
    "# find hyperparameter\n",
    "epochs = [30]\n",
    "batch_size = [64]\n",
    "dropout = [0.2]\n",
    "activation = ['relu']\n",
    "lr = [0.0001,0.001,0.002,0.003,0.01,0.1,0.2] \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "model = KerasClassifier(build_fn=create_cnn_model,verbose=0)\n",
    "\n",
    "start = time()\n",
    "param_grid = dict(dropout=dropout,epochs=epochs,batch_size=batch_size,activation=activation,learn_rate=lr)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3).fit(X_train[:,:,:,None],y_train)\n",
    "end = time()\n",
    "\n",
    "print(f'time: {end-start} sec')\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "rank = grid.cv_results_['rank_test_score']\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']  \n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with:%r\"%(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L47Ld3Y4_MpH",
   "metadata": {
    "id": "L47Ld3Y4_MpH"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yirb66Us_IcT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yirb66Us_IcT",
    "outputId": "b0b35d69-9cf9-4af9-b07d-11adfd0685b9"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(activation='relu',dropout=0.2,optimizer='RMSprop',learn_rate=0.002):\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "    model = None\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, 5, input_shape=(X_train.shape[1], X_train.shape[2], 1), activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 5, activation=activation,padding='same'))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(64, activation=activation))\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(keras.layers.Dense(len(np.unique(df['label'])), activation='softmax'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(lr=learn_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "start = time()\n",
    "model_cnn = create_cnn_model(activation='relu',dropout=0.2,optimizer='RMSprop',learn_rate=0.002)\n",
    "history = model_cnn.fit(X_train[:,:,:,None], y_train, epochs=30, validation_data=(X_valid[:,:,:,None],y_valid),batch_size=64,verbose=1)\n",
    "end = time()\n",
    "print(f'time: {end-start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sf4WWJV3__D7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf4WWJV3__D7",
    "outputId": "42a61ee6-faa3-42f5-ad71-e811dbef66da"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(f'Test Accuracy: {model_cnn.evaluate(X_test[:,:,:,None],y_test,verbose=0)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BXn8UvSpAOw4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "BXn8UvSpAOw4",
    "outputId": "a46f1649-167c-4629-9c30-c7014c78220d"
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "# plot the accuracy and loss plots between training and validation data\n",
    "# verify overfitting or underfit \n",
    "\n",
    "model_cnn = create_cnn_model(activation='relu',dropout=0.2,optimizer='RMSprop',learn_rate=0.002)\n",
    "history = model_cnn.fit(X_train[:,:,:,None], y_train, epochs=100, validation_data=(X_valid[:,:,:,None],y_valid),batch_size=64,verbose=0)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "x = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(x,acc,'b',label='Training accuracy')\n",
    "plt.plot(x,val_acc,'r',label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(x,loss,'b',label='Training loss')\n",
    "plt.plot(x,val_loss,'r',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drxe7zX2AVxp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drxe7zX2AVxp",
    "outputId": "1c0a1e26-c9d3-4b26-cc2d-8c5966a1db6a"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "predicted_classes = np.argmax(np.round(model_cnn.predict(X_test[:,:,:,None])),axis=1)\n",
    "correct = np.where(predicted_classes==y_test)[0]\n",
    "target_names = [f\"Class {label}\" for label in range(len(np.unique(df['label'])))]\n",
    "\n",
    "print(f\"From {len(y_test)} labels're founding {len(correct)} correct labels.\")\n",
    "print(f'Accuracy: {len(correct)/len(y_test)}')\n",
    "print('')\n",
    "print(classification_report(y_test, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TcOE-8tFgar4",
   "metadata": {
    "id": "TcOE-8tFgar4"
   },
   "outputs": [],
   "source": [
    "index=[]\n",
    "true = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 0 or y_test[i] == 8 or y_test[i] == 39:\n",
    "        index.append(i)\n",
    "        true.append(y_test[i])\n",
    "\n",
    "pred=[]\n",
    "for i in index:\n",
    "    pred.append(predicted_classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ti-czTiTigyG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ti-czTiTigyG",
    "outputId": "1813387c-0c4e-44d7-f21b-b2a36dfb284e"
   },
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OuNS4xKoiqa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuNS4xKoiqa2",
    "outputId": "9f87f61e-51b2-4614-e729-2658d0eb32e4"
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vy2dlO9xhvT6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "vy2dlO9xhvT6",
    "outputId": "c2c2779a-ac1d-41d9-d146-f8108b7f5f2b"
   },
   "outputs": [],
   "source": [
    "!wget -q https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
    "\n",
    "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf')\n",
    "mpl.rc('font', family='TH Sarabun New', size=8)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(true, pred)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf_matrix, annot=True, xticklabels=['กระชาย','ไข่น้ำ','น้อยหน่า','ผักตำลึง','ใบชะพลู1'],yticklabels=['กระชาย','ไข่น้ำ','น้อยหน่า','ผักตำลึง','ใบชะพลู1'],cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ExkYoE9LXq6I",
   "metadata": {
    "id": "ExkYoE9LXq6I"
   },
   "source": [
    "## Other people \n",
    "men and woman each 10 audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AYxW624FZZdM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYxW624FZZdM",
    "outputId": "de05af18-c67f-4d6a-9b3e-1ccf71b1e7a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(77)\n",
    "\n",
    "random_fruit_veget = np.random.choice(np.unique(df['description']),10,replace=False).tolist()\n",
    "print(random_fruit_veget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XTRoVzSzX3XM",
   "metadata": {
    "id": "XTRoVzSzX3XM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Audio data source\n",
    "other_source = {'audio_time':[],\n",
    "                'sampling_rate':[],\n",
    "                'feature_extraction':[],\n",
    "                'label':[],\n",
    "                'description':[]}\n",
    "\n",
    "for types in random_fruit_veget:\n",
    "    audio_files = glob('/content/Project_499/Record_other_audio/' + str(types) + '/*.wav')\n",
    "\n",
    "    for audio in audio_files:\n",
    "        y,sr = librosa.load(audio,duration=5,offset=0)\n",
    "        other_source['description'].append(str(types))\n",
    "        other_source['audio_time'].append(y)\n",
    "        other_source['sampling_rate'].append(sr)\n",
    "        other_source['feature_extraction'].append(feature_mfcc(y,sr))\n",
    "\n",
    "other_source['label'] = [18,18,14,14,39,39,44,44,37,37,50,50,25,25,55,55,40,40,38,38]\n",
    "other_df = pd.DataFrame.from_dict(other_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rQ6EclMVZCeE",
   "metadata": {
    "id": "rQ6EclMVZCeE"
   },
   "outputs": [],
   "source": [
    "other_X_test = np.array(other_df['feature_extraction'].to_list())\n",
    "other_y_test = np.array(other_df['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uG_isU-4c97L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG_isU-4c97L",
    "outputId": "ce5e5ce2-49b4-426f-ae06-132d78ed414c"
   },
   "outputs": [],
   "source": [
    "# classification report\n",
    "predicted_classes = np.argmax(np.round(model_cnn.predict(other_X_test[:,:,:,None])),axis=1)\n",
    "correct = np.where(predicted_classes==other_y_test)[0]\n",
    "target_names = [f\"Class {label}\" for label in np.unique(other_source['label'])]\n",
    "\n",
    "print(f\"From {len(other_y_test)} labels're founding {len(correct)} correct labels.\")\n",
    "print(f'Accuracy: {len(correct)/len(other_y_test)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Project_499_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
